{
 "metadata": {
  "name": "",
  "signature": "sha256:acd14ad78e99e1239ea2014327cf49c3c0dbdbe500c439ccdc88e9f0a84067a4"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Figures for:\n",
      "\n",
      "These are not the k-mers you are looking for: efficient online k-mer counting using a probabilistic data structure\n",
      "==================================================================================================================\n",
      "\n",
      "See the paper at: http://arxiv.org/abs/1309.2975"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Table of Contents\n",
      "=================\n",
      "\n",
      "[Figure 1 - time usage of different k-mer counting tools](#Figure-1---time-usage-of-different-k-mer-counting-tools)\n",
      "\n",
      "[Figure 2 - memory usage of different k-mer counting tools](#Figure-2---Memory-usage-of-different-k-mer-counting-tools)\n",
      "\n",
      "[Figure 3 - Disk storage usage of different k-mer counting tools](#Figure-3---Disk-storage-usage-of-different-k-mer-counting-tools)\n",
      "\n",
      "[Figure 4 - Comparison of time it takes to count k-mers](#Figure-4---Comparison-of-time-it-takes-to-count-k-mers)\n",
      "\n",
      "[Figure 5 - relation between average miscount and counting error rate](#Figure-5---relation-between-average-miscount-and-counting-error-rate)\n",
      "\n",
      "[Figure 6 - counting error rate vs miscount](#Figure-6---counting-error-rate-vs-miscount)\n",
      "\n",
      "[Figure 7 - Percentage of the unique k-mers starting in different position in reads](#Figure-7---Percentage-of-the-unique-k-mers-starting-in-different-position-in-reads)\n",
      "\n",
      "[Tables](#Tables)\n",
      "\n",
      "[Supplimentary - determine the optimal parameters of hash tables to use](#Supplimentary---determine-the-optimal-parameters-of-hash-tables-to-use)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%pylab inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Populating the interactive namespace from numpy and matplotlib\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import seaborn"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "ImportError",
       "evalue": "No module named seaborn",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-2-085c0287ecb5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;31mImportError\u001b[0m: No module named seaborn"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import seaborn as sns"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# you may need to:\n",
      "#\n",
      "#!pip install --upgrade six\n",
      "# !pip install --upgrade statsmodels\n",
      "#\n",
      "# and then restart the ipython notebook kernel."
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy\n",
      "import seaborn as sns\n",
      "\n",
      "import matplotlib as mpl\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "datadir = '../data/'\n",
      "figsize(12,6)\n",
      "\n",
      "# also try \"whitegrid\" for white background\n",
      "sns.set(style=\"darkgrid\", font=\"Serif\")\n",
      "sns.set_color_palette(\"deep\", n_colors=10, desat=.8)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# palette can be changed around\n",
      "# see other options: http://wiki.scipy.org/Cookbook/Matplotlib/Show_colormaps\n",
      "c_khmer, c_ty, c_jf, c_dsk, c_kmc, c_bfc, c_t, c_k = sns.color_palette(\"Set1\", 8)\n",
      "\n",
      "# set all widths the same\n",
      "lineparams = {'markersize':8.0, 'lw':2.0}\n",
      "\n",
      "# keep each tool's format consistent\n",
      "s_khmer = {'marker': 'o', 'c': c_khmer}\n",
      "s_khmer.update(lineparams)\n",
      "\n",
      "s_ty = {'marker': '^', 'c': c_ty}\n",
      "s_ty.update(lineparams)\n",
      "\n",
      "s_jf = {'marker': 'h', 'c': c_jf}\n",
      "s_jf.update(lineparams)\n",
      "\n",
      "s_dsk = {'marker': 's', 'c': c_dsk}\n",
      "s_dsk.update(lineparams)\n",
      "\n",
      "s_kmc = {'marker': 'v', 'c': c_kmc}\n",
      "s_kmc.update(lineparams)\n",
      "\n",
      "s_bfc = {'marker': 'D', 'c': c_bfc}\n",
      "s_bfc.update(lineparams)\n",
      "\n",
      "s_t = {'marker': 'p', 'c': c_t}\n",
      "s_t.update(lineparams)\n",
      "\n",
      "s_k = {'marker': 'p', 'c': c_k}\n",
      "s_t.update(lineparams)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_time_mem(filename):\n",
      "    \"Extract the user time and max memory as generated by 'time' command\"\n",
      "    for line in open(filename):\n",
      "        line = line.rstrip()\n",
      "        if 'system' in line:\n",
      "            fields1 = line.split('user')\n",
      "            time1 = float(fields1[0])\n",
      "            fields1b = line.split('system')[0].split()[-1]\n",
      "            time2 = float(fields1b)\n",
      "            \n",
      "            walltime = line.split('elapsed')[0].split()[-1].rsplit(':')\n",
      "            assert len(walltime) <= 3\n",
      "            hours = 0.\n",
      "            minutes = 0.\n",
      "            seconds = walltime[-1]\n",
      "            if len(walltime) == 3:\n",
      "                hours = float(walltime[0])\n",
      "                minutes = float(walltime[1])\n",
      "            elif len(walltime) == 2:\n",
      "                minutes = float(walltime[0])\n",
      "                \n",
      "            wall_seconds = hours*60*60 + minutes*60 + float(walltime[1])\n",
      "            \n",
      "            time = wall_seconds\n",
      "            fields2 = line.split('avgdata ')\n",
      "            fields3 = fields2[1].split('max')\n",
      "            mem = str(int(fields3[0])/4)\n",
      "            return float(time), float(mem)\n",
      "    raise Exception(filename)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# read time files\n",
      "\n",
      "\n",
      "\n",
      "mkindex_time={}\n",
      "mkindex_mem={}\n",
      "suffix_time={}\n",
      "suffix_mem={}\n",
      "\n",
      "# tallymer runtime info\n",
      "# part=1 k=22 \n",
      "\n",
      "for i1 in range(1,6):\n",
      "    for i2 in [1]:\n",
      "        for i3 in [22]:\n",
      "            name = \"%d_%d_%d\" % (i1, i2, i3)\n",
      "            filename = 'mkindex_%d_part%d_%d.time' % (i1, i2, i3)\n",
      "            filename = datadir + filename\n",
      "            mkindex_time[name],mkindex_mem[name] = get_time_mem(filename)\n",
      "\n",
      "        name = \"%d_%d\" % (i1, i2)\n",
      "        filename = datadir + 'suffix_%d_part%d.time' % (i1, i2)\n",
      "        suffix_time[name],suffix_mem[name] = get_time_mem(filename)\n",
      "\n",
      "# read jellyfish \n",
      "# k=22 and k=31\n",
      "\n",
      "jelly_count_mem = {}\n",
      "jelly_count_time = {}\n",
      "for i1 in range(1,6):\n",
      "    for i2 in [22,31]:\n",
      "        name = \"%d_%d\" % (i1, i2)\n",
      "        filename = datadir + 'jelly_%d_%d.time1' % (i1, i2)\n",
      "        jelly_count_time[name],jelly_count_mem[name] = get_time_mem(filename)\n",
      "\n",
      " \n",
      "jelly_hist_mem = {}\n",
      "jelly_hist_time = {}\n",
      "for i1 in range(1,6):\n",
      "    for i2 in [22,31]:\n",
      "        name = \"%d_%d\" % (i1, i2)\n",
      "        filename = datadir + 'jelly_%d_%d.time2' % (i1, i2)\n",
      "        jelly_hist_time[name],jelly_hist_mem[name] = get_time_mem(filename)\n",
      "\n",
      "# DSK use k=22\n",
      "\n",
      "dsk_mem = {}\n",
      "dsk_time = {}\n",
      "for i1 in range(1,6):\n",
      "    for i2 in [22]:\n",
      "        name = \"%d_%d\" % (i1, i2)\n",
      "        filename = datadir+'dsk_%d_%d.time' % (i1, i2)\n",
      "        dsk_time[name], dsk_mem[name] = get_time_mem(filename)\n",
      "\n",
      "# khmer use k=22 only, error rate=1%\uff0c 5% and 20%\n",
      "\n",
      "khmer_mem1 = {}\n",
      "khmer_time1 = {}\n",
      "\n",
      "for i1 in range(1,6):\n",
      "    for i2 in [1,5,20]:\n",
      "        for i3 in [22]:\n",
      "            name = \"%d_%d_%d\" % (i1, i2, i3)\n",
      "            filename = datadir +'bloom_%d_%d_%d.hist.time' % (i1, i2, i3)\n",
      "            khmer_time1[name],khmer_mem1[name] = get_time_mem(filename)\n",
      "\n",
      "    \n",
      "#khmer_mem2 = {}\n",
      "#khmer_time2 = {}\n",
      "\n",
      "#for i1 in range(1,6):\n",
      "#    for i2 in [1,5,20]:\n",
      "#        for i3 in [22]:\n",
      "#            name = \"%d_%d_%d\" % (i1, i2, i3)\n",
      "#            filename = datadir +'bloom_%d_%d_%d.time2' % (i1, i2, i3)\n",
      "#            khmer_time2[name],khmer_mem2[name] = get_time_mem(filename)\n",
      "\n",
      "\n",
      "kmc_mem = {}\n",
      "kmc_time = {}\n",
      "for i1 in range(1,6):\n",
      "    for i2 in [22]:\n",
      "        name = \"%d_%d\" % (i1, i2)\n",
      "        filename = datadir+'kmc_%d_%d.time' % (i1, i2)\n",
      "        kmc_time[name], kmc_mem[name] = get_time_mem(filename)\n",
      "        \n",
      "\n",
      "kmc_dump_mem = {}\n",
      "kmc_dump_time = {}\n",
      "for i1 in range(1,6):\n",
      "    for i2 in [22]:\n",
      "        name = \"%d_%d\" % (i1, i2)\n",
      "        filename = datadir+'kmc_dump_%d_%d.time' % (i1, i2)\n",
      "        kmc_dump_time[name], kmc_dump_mem[name] = get_time_mem(filename)\n",
      "        \n",
      "bfcount_mem = {}\n",
      "bfcount_time = {}\n",
      "for i1 in range(1,6):\n",
      "    for i2 in [22]:\n",
      "        name = \"%d_%d\" % (i1, i2)\n",
      "        filename = datadir+'BF_count_%d.time' % (i1)\n",
      "        bfcount_time[name], bfcount_mem[name] = get_time_mem(filename)\n",
      "        \n",
      "bfdump_mem = {}\n",
      "bfdump_time = {}\n",
      "for i1 in range(1,6):\n",
      "    for i2 in [22]:\n",
      "        name = \"%d_%d\" % (i1, i2)\n",
      "        filename = datadir+'BF_dump_%d.time' % (i1)\n",
      "        bfdump_time[name], bfdump_mem[name] = get_time_mem(filename)\n",
      "        \n",
      "turtle_mem = {}\n",
      "turtle_time = {}\n",
      "for i1 in range(1,6):\n",
      "    for i2 in [22]:\n",
      "        name = \"%d_%d\" % (i1, i2)\n",
      "        filename = datadir+'turtle_%d_%d.time' % (i1, i2)\n",
      "        turtle_time[name], turtle_mem[name] = get_time_mem(filename)       \n",
      "\n",
      "kanalyze_mem = {}\n",
      "kanalyze_time = {}\n",
      "for i1 in range(1,6):\n",
      "        name = \"%d_%d\" % (i1, 22)\n",
      "        filename = datadir+'kanalyze_%d.time' % (i1,)\n",
      "        print filename\n",
      "        kanalyze_time[name], kanalyze_mem[name] = get_time_mem(filename)       \n",
      "print kanalyze_mem\n",
      "print \"1\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# number of unique 22-mers in different data sets\n",
      "\n",
      "def get_total_kmers(filename):\n",
      "    total = 0\n",
      "    for line in open(filename):\n",
      "        line = line.rstrip()\n",
      "        fields = line.split()\n",
      "        total = total + int(fields[1])\n",
      "    return total\n",
      "total_list = []\n",
      "for i in range(1,6):\n",
      "    filename = datadir+'jelly_%d_22.hist' % (i)\n",
      "    total = get_total_kmers(filename)\n",
      "    total_list.append(float(total) / 1e9)\n",
      "\n",
      "print kmc_mem,kmc_time,\"test\"\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Figure 1 - time usage of different k-mer counting tools"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "time_khmer = [] # 1% error rate , k=22\n",
      "time_tallymer = [] # k=22,  time usage is the same for part=1 or part=4, only use part=1 here\n",
      "time_jellyfish_k22 = [] # use k=22, but memory change with different k size. k=31. \n",
      "time_dsk = [] # use k=22.\n",
      "time_kmc = []\n",
      "time_BF = []\n",
      "time_turtle = []\n",
      "time_kanalyze = []\n",
      "for i in range(1,6):\n",
      "    time_khmer.append(khmer_time1[str(i)+'_1_22'])\n",
      "    time_tallymer.append(suffix_time[str(i)+'_1']+mkindex_time[str(i)+'_1_22'])\n",
      "    time_jellyfish_k22.append(jelly_count_time[str(i)+'_22'] + jelly_hist_time[str(i)+'_22'])\n",
      "    time_dsk.append(dsk_time[str(i)+'_22'])\n",
      "    time_kmc.append(kmc_time[str(i)+'_22']+kmc_dump_time[str(i)+'_22'])\n",
      "    time_BF.append(bfcount_time[str(i)+'_22']+ bfdump_time[str(i)+'_22'])\n",
      "    time_turtle.append(turtle_time[str(i)+'_22'])\n",
      "    time_kanalyze.append(kanalyze_time[str(i)+'_22'])\n",
      "#for i in range(1,3):\n",
      " #   L_turtle.append(turtle_time[str(i)+'_22'])\n",
      "time_khmer"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# fig 1\n",
      "f, axarr = plt.subplots(2, sharex=True)\n",
      "f.set_size_inches(10,7)\n",
      "\n",
      "read_counts = [9744399, 19488798, 29233197, 38977596, 48721995]    \n",
      "read_counts = [ float(x) / 1e6 for x in read_counts ]\n",
      "\n",
      "#############\n",
      "# top subplot\n",
      "#############\n",
      "\n",
      "ax = axarr[0]\n",
      "ax.set_ylabel('Time (s)')\n",
      "\n",
      "ax.plot(read_counts, time_khmer,'-', label='khmer (1% error rate)', **s_khmer)\n",
      "#ax.plot(read_counts, time_tallymer,'-', label='Tallymer', **s_ty)\n",
      "ax.plot(read_counts, time_jellyfish_k22,'-', label='Jellyfish', **s_jf)\n",
      "ax.plot(read_counts, time_dsk,'-', label='DSK', **s_dsk)\n",
      "ax.plot(read_counts, time_kmc,'-', label='KMC', **s_kmc)\n",
      "ax.plot(read_counts, time_BF,'-', label='BFCounter', **s_bfc)\n",
      "ax.plot(read_counts, time_turtle,'-', label='scTurtle', **s_t)\n",
      "#ax.plot(read_counts, time_kanalyze,'-', label='kAnalyze', **s_k)\n",
      "ax.set_xlim(0,50)\n",
      "ax.legend(loc='best') #,prop={'size':8})\n",
      "fig_file = '../figure/time_benchmark-a.eps'\n",
      "plt.savefig(fig_file,dpi=300)\n",
      "\n",
      "################\n",
      "# bottom subplot\n",
      "################\n",
      "\n",
      "ax = axarr[1]\n",
      "ax.plot(read_counts, time_khmer,'-', label='khmer (1% error rate)', **s_khmer)\n",
      "ax.plot(read_counts, time_tallymer,'-', label='Tallymer', **s_ty)\n",
      "#ax.plot(read_counts, time_jellyfish_k22,'-', label='Jellyfish', **s_jf)\n",
      "#ax.plot(read_counts, time_dsk,'-', label='DSK', **s_dsk)\n",
      "#ax.plot(read_counts, time_kmc,'-', label='KMC', **s_kmc)\n",
      "#ax.plot(read_counts, time_BF,'-', label='BFCounter', **s_bfc)\n",
      "ax.plot(read_counts, time_turtle,'-', label='scTurtle', **s_t)\n",
      "ax.plot(read_counts, time_kanalyze,'-', label='KAnalyze', **s_k)\n",
      "ax.set_xlim(0,50)\n",
      "ax.set_xlabel('Total number of reads (millions)')\n",
      "ax.set_ylabel('Time (s)')\n",
      "\n",
      "ax.legend(loc='best') #,prop={'size':8})\n",
      "#fig_file = '../figure/time_benchmark.eps'\n",
      "fig_file = '../figure/time_benchmark.pdf'\n",
      "\n",
      "plt.savefig(fig_file,dpi=300)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Figure 2 - Memory usage of different k-mer counting tools"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mem_khmer_1p = [] # 1% error rate , k=22\n",
      "mem_khmer_5p = [] # 5% error rate, k=22\n",
      "mem_khmer_20p = [] # 20% error rate, k=22\n",
      "mem_tallymer = [] # k=22, pick biggest memory, suffix 1 part and 4 parts different memory ,but all smaller than mkindex step(same with part1 or part4). \n",
      "mem_jellyfish_k22 = [] # use k=22, but memory change with different k size. k=31. \n",
      "mem_jellyfish_k31 = []\n",
      "mem_dsk = [] # use k=22.\n",
      "mem_kmc = []\n",
      "mem_BF = []\n",
      "mem_turtle = []\n",
      "mem_kanalyze = []\n",
      "\n",
      "for i in range(1,6):\n",
      "\n",
      "    mem_khmer_1p.append(khmer_mem1[str(i)+'_1_22']/1000000)\n",
      "    mem_khmer_5p.append(khmer_mem1[str(i)+'_5_22']/1000000)\n",
      "    mem_khmer_20p.append(khmer_mem1[str(i)+'_20_22']/1000000)\n",
      "    mem_tallymer.append(mkindex_mem[str(i)+'_1_22']/1000000) # memory usage of mkindex is always bigger than suffix(part1/4)\n",
      "    if jelly_count_mem[str(i)+'_22'] > jelly_hist_mem[str(i)+'_22']:\n",
      "        mem_jellyfish_k22.append(jelly_count_mem[str(i)+'_22']/1000000)\n",
      "    else:\n",
      "        mem_jellyfish_k22.append(jelly_hist_mem[str(i)+'_22']/1000000)\n",
      "\n",
      "    if jelly_count_mem[str(i)+'_31'] > jelly_hist_mem[str(i)+'_31']:\n",
      "        mem_jellyfish_k31.append(jelly_count_mem[str(i)+'_31']/1000000)\n",
      "    else:\n",
      "        mem_jellyfish_k31.append(jelly_hist_mem[str(i)+'_31']/1000000)\n",
      "        \n",
      "    mem_dsk.append(dsk_mem[str(i)+'_22']/1000000)\n",
      "    \n",
      "    if kmc_mem[str(i)+'_22'] > kmc_dump_mem[str(i)+'_22']:\n",
      "        mem_kmc.append(kmc_mem[str(i)+'_22']/1000000)\n",
      "    else:\n",
      "        mem_kmc.append(kmc_dump_mem[str(i)+'_22']/1000000)\n",
      " \n",
      "    if bfcount_mem[str(i)+'_22'] > bfdump_mem[str(i)+'_22']:\n",
      "        mem_BF.append(bfcount_mem[str(i)+'_22']/1000000)\n",
      "    else:\n",
      "        mem_BF.append(bfdump_mem[str(i)+'_22']/1000000)\n",
      "    mem_turtle.append(turtle_mem[str(i)+'_22']/1000000)\n",
      "    mem_kanalyze.append(kanalyze_mem[str(i)+'_22']/1000000)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# 2. memory usage of different k-mer counting tools, growing\n",
      "\n",
      "f, axarr = plt.subplots(2, sharex=True)\n",
      "f.set_size_inches(10,7)\n",
      "\n",
      "\n",
      "#############\n",
      "# top subplot\n",
      "#############\n",
      "\n",
      "ax = axarr[0]\n",
      "ax.set_xlabel('Total number of distinct k-mers (billions)')\n",
      "ax.set_ylabel('Memory usage(G)')\n",
      "\n",
      "ax.plot(total_list, mem_khmer_1p,'-', label='khmer (1% error rate)', **s_khmer)\n",
      "ax.plot(total_list, mem_khmer_5p,'--', label='khmer (5% error rate)', **s_khmer)\n",
      "ax.plot(total_list, mem_khmer_20p,':', label='khmer (20% error rate)', **s_khmer)\n",
      "#ax.plot(total_list, mem_tallymer,'-', label='Tallymer', **s_ty)\n",
      "#ax.plot(total_list, mem_jellyfish_k22,'--', label='Jellyfish k=22', **s_jf)\n",
      "#ax.plot(total_list, mem_jellyfish_k31,'-', label='Jellyfish k=31', **s_jf)\n",
      "ax.plot(total_list, mem_dsk,'-', label='DSK', **s_dsk)\n",
      "ax.plot(total_list, mem_kmc,'-', label='KMC', **s_kmc)\n",
      "#ax.plot(total_list, mem_BF,'-', label='BFCounter', **s_bfc)\n",
      "#ax.plot(total_list, mem_turtle,'-', label='scTurtle', **s_t)\n",
      "ax.plot(total_list, mem_kanalyze,'-', label='KAnalyze', **s_k)\n",
      "#print L_turtle\n",
      "ax.set_xlim(0,2.3)\n",
      "ax.set_ylim(0,15)\n",
      "ax.legend(loc='upper left') #,prop={'size':8})\n",
      "\n",
      "################\n",
      "# bottom subplot\n",
      "################\n",
      "\n",
      "ax = axarr[1]\n",
      "ax.set_ylabel('Memory usage(G)')\n",
      "\n",
      "ax.plot(total_list, mem_khmer_1p,'-', label='khmer (1% error rate)', **s_khmer)\n",
      "ax.plot(total_list, mem_khmer_5p,'--', label='khmer (5% error rate)', **s_khmer)\n",
      "ax.plot(total_list, mem_khmer_20p,':', label='khmer (20% error rate)', **s_khmer)\n",
      "#ax.plot(total_list, mem_tallymer,'-', label='Tallymer', **s_ty)\n",
      "ax.plot(total_list, mem_jellyfish_k22,'--', label='Jellyfish', **s_jf)\n",
      "#ax.plot(total_list, mem_jellyfish_k31,'-', label='Jellyfish k=31', **s_jf)\n",
      "#ax.plot(total_list, mem_dsk,'-', label='DSK', **s_dsk)\n",
      "#ax.plot(total_list, mem_kmc,'-', label='KMC', **s_kmc)\n",
      "ax.plot(total_list, mem_BF,'-', label='BFCounter', **s_bfc)\n",
      "ax.plot(total_list, mem_turtle,'-', label='scTurtle', **s_t)\n",
      "#ax.plot(total_list, mem_kanalyze,'-', label='kanalyze', **s_k)\n",
      "ax.set_xlim(0,2.3)\n",
      "ax.legend(loc='upper left') #,prop={'size':8})\n",
      "\n",
      "\n",
      "fig_file = '../figure/memory_benchmark.pdf'\n",
      "#fig_file = '../figure/memory_benchmark.eps'\n",
      "plt.savefig(fig_file,dpi=300)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "memory usage of khmer is larger than predicted, which is the \"maxresident\" in time output."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Figure 3 - Disk storage usage of different k-mer counting tools"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "\n",
      "def get_total_kmers(filename):\n",
      "    total = 0\n",
      "    for line in open(filename):\n",
      "        line = line.rstrip()\n",
      "        fields = line.split()\n",
      "        total = total + int(fields[1])\n",
      "    return total\n",
      "total_list = []\n",
      "for i in range(1,6):\n",
      "    filename = datadir+'jelly_%d_22.hist' % (i)\n",
      "    total = get_total_kmers(filename)\n",
      "    total_list.append(total)\n",
      "\n",
      "print total_list\n",
      "\n",
      "\n",
      "file_ls = open(\"../data/ls.log\",'r')\n",
      "size = {}\n",
      "file_ls.readline()\n",
      "for line in file_ls:\n",
      "#    print line\n",
      "    line = line.rstrip()\n",
      "    fields = line.split()\n",
      "    size[fields[-1]] = int(fields[-4])\n",
      "\n",
      "\n",
      "# BFCount: \n",
      "# ----\n",
      "# bloom filter based, only count non-unique k-mers: (frequency>1)\n",
      "# \n",
      "# two steps: \n",
      "# \n",
      "# - BFCounter count - counting     - output temparary binary file\n",
      "# - BFCounter dump - get the frequency of non-unique k-mers - write to hard disk the text files\n",
      "# \n",
      "# Estimated number of k-mers (upper bound) was used, which is acquired from actual distinct k-mers in test datasets.\n",
      "# This will influence the memory usage and disk usage.\n",
      "\n",
      "\n",
      "\n",
      "L_BF = []\n",
      "for i in range(1,6):\n",
      "    size_total = size['iowa.'+str(i)]+size['iowa.'+str(i)+'.txt']\n",
      "    L_BF.append(size_total/1000000000.0)\n",
      "print L_BF\n",
      "    \n",
      "\n",
      "\n",
      "# KMC\n",
      "# ----------\n",
      "# like DSK, hard disk based\n",
      "# \n",
      "# two steps:\n",
      "# \n",
      "# - kmc - the main program for counting k-mer occurrences - output temparary binary files \\*.kmc_pre and \\*.kmc_suf\n",
      "# - kmc_dump - the program listing k-mers in a database produced by kmc - output text file to contain k-mers and counts\n",
      "# \n",
      "\n",
      "\n",
      "L_KMC = []\n",
      "for i in range(1,6):\n",
      "    size_total = size['kmc_'+str(i)+'_22.out.kmc_pre']+size['kmc_'+str(i)+'_22.out.kmc_suf']+size['kmc_dump_'+str(i)+'_22.out']\n",
      "    L_KMC.append(size_total/1000000000.0)\n",
      "print L_KMC\n",
      "    \n",
      "\n",
      "\n",
      "# Turtle\n",
      "# --------\n",
      "# like BFCounter, only counts frequent k-mers, count>1\n",
      "# \n",
      "# based on enhanced Bloom Filter\n",
      "# \n",
      "# Two subprograms:\n",
      "# \n",
      "# - scTurtle: reports k-mers with frequency >1 with counts\n",
      "# - aTurtle: reports all k-mers with counts\n",
      "# - cTurtle: reports k-mers with frequency >1 but not their counts\n",
      "# \n",
      "# Tried aTurtle , failed to finish dataset 3, 4, 5\n",
      "# \n",
      "# Tried scTurtle, the same, shown in figure\n",
      "# \n",
      "\n",
      "\n",
      "L_Turtle = []\n",
      "for i in range(1,6):\n",
      "    size_total = 0\n",
      "    for k in range(7):\n",
      "        size_total = size_total+ size['turtle_'+str(i)+'_22.out'+str(k)]\n",
      "        \n",
      "    L_Turtle.append(size_total/1000000000.0)\n",
      "print L_Turtle\n",
      "\n",
      "\n",
      "\n",
      "# kanalyze , use 2G memory, also lots of temperatre files, as large as output file\n",
      "\n",
      "\n",
      "L_kanalyze = []\n",
      "for i in range(1,6):\n",
      "    size_total = size['kanalyze_'+str(i)+'.out']\n",
      "    L_kanalyze.append(size_total/1000000000.0)\n",
      "print L_kanalyze\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# 3. disk usage of different k-mer counting tools\n",
      "fig = plt.figure()\n",
      "ax = fig.add_subplot(111)\n",
      "fig.set_size_inches(10,7)\n",
      "\n",
      "\n",
      "# from size of intermediant files on hard disk, will modify to automatically generate\n",
      "L_khmer = [5.5,11,15,18,21] # 1% error rate , k=22\n",
      "L_tallymer = [7.8,17,23,28,36] # k=22, pick biggest memory, suffix 1 part and 4 parts different memory ,but all smaller than mkindex step. \n",
      "L_jellyfish_k22 = [5.3,9.9,14,17,20] # use k=22, but memory change with different k size. k=31. \n",
      "L_dsk = [1.1,2.1,3.0,3.8,4.7] # use k=22. by default, use the size of reads file as disk usage parameter\n",
      "L_khmer_gz = [1284585409. / 1e9,2491325096. / 1e9, 3439743439./1e9,4254327173./1e9,5151176537./1e9]\n",
      "\n",
      "ax.set_xlabel('Total number of distinct k-mers')\n",
      "ax.set_ylabel('Disk usage (GB)')\n",
      "\n",
      "ax.plot(total_list,L_khmer, linestyle='-', label='khmer (1%)*', **s_khmer)\n",
      "ax.plot(total_list,L_khmer_gz, linestyle='--', label='khmer (1%), compressed', **s_khmer)\n",
      "ax.plot(total_list,L_tallymer, linestyle='-', label='Tallymer', **s_ty)\n",
      "ax.plot(total_list,L_jellyfish_k22, linestyle='-', label='Jellyfish', **s_jf)\n",
      "ax.plot(total_list,L_dsk, linestyle='-', label='DSK', **s_dsk)\n",
      "ax.plot(total_list,L_KMC,linestyle='-', label='KMC',**s_kmc)\n",
      "ax.plot(total_list,L_BF,linestyle='-', label='BFCounter',**s_bfc)\n",
      "ax.plot(total_list,L_Turtle,linestyle='-', label='scTurtle',**s_t)\n",
      "ax.plot(total_list,L_kanalyze,'-', label='KAnalyze', **s_k)\n",
      "\n",
      "ax.set_ylim(0,60)\n",
      "ax.legend(loc='upper left') #,prop={'size':8})\n",
      "#fig_file = '../figure/disk_benchmark.eps'\n",
      "fig_file = '../figure/disk_benchmark.pdf'\n",
      "plt.savefig(fig_file,dpi=300)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Figure 4 - Comparison of time it takes to count k-mers"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tally_count = [ get_time_mem('../data/1_part1_22.count.time')[0],\n",
      "                get_time_mem('../data/2_part1_22.count.time')[0],\n",
      "                get_time_mem('../data/3_part1_22.count.time')[0],\n",
      "                get_time_mem('../data/4_part1_22.count.time')[0],\n",
      "                get_time_mem('../data/5_part1_22.count.time')[0] ]\n",
      "\n",
      "khmer_count = [ get_time_mem('../data/bloom_1_1_22.count.time')[0],\n",
      "                get_time_mem('../data/bloom_2_1_22.count.time')[0],\n",
      "                get_time_mem('../data/bloom_3_1_22.count.time')[0],\n",
      "                get_time_mem('../data/bloom_4_1_22.count.time')[0],\n",
      "                get_time_mem('../data/bloom_5_1_22.count.time')[0] ]\n",
      "\n",
      "jelly_count = [ get_time_mem('../data/jelly_1_22.count.time')[0],\n",
      "                get_time_mem('../data/jelly_2_22.count.time')[0],\n",
      "                get_time_mem('../data/jelly_3_22.count.time')[0],\n",
      "                get_time_mem('../data/jelly_4_22.count.time')[0],\n",
      "                get_time_mem('../data/jelly_5_22.count.time')[0] ]\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fig = plt.figure()\n",
      "ax = fig.add_subplot(111)\n",
      "fig.set_size_inches(6.83,4)\n",
      "\n",
      "ax.plot(total_list, khmer_count, linestyle='-', label='khmer (1%)', **s_khmer)\n",
      "ax.plot(total_list, tally_count, linestyle='-', label='Tallymer', **s_ty)\n",
      "ax.plot(total_list, jelly_count, linestyle='-', label='Jellyfish', **s_jf)\n",
      "\n",
      "ax.legend(loc='best',prop={'size':8})\n",
      "ax.set_ylim(0,1600)\n",
      "ax.set_xlabel('Number of k-mers in database')\n",
      "ax.set_ylabel('Time (s)')\n",
      "fig_file = '../figure/count_benchmark.eps'\n",
      "plt.savefig(fig_file,dpi=300)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Figure 5 - relation between average miscount and counting error rate"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ht_size = \"100000,200000,400000,600000,800000,1000000,1200000,1400000,1800000,2200000,2600000,3000000,4000000,6000000\"\n",
      "HT_SIZE_array = map(int,ht_size.split(','))\n",
      "\n",
      "\n",
      "file_obj = open(datadir+'fp_assessment.out','r')\n",
      "lines = file_obj.readlines()\n",
      "result1 = [map(float,lines[1].split()),map(float,lines[2].split())]\n",
      "result2 = [map(float,lines[5].split()),map(float,lines[6].split())]\n",
      "result3 = [map(float,lines[9].split()),map(float,lines[10].split())]\n",
      "result4 = [map(float,lines[13].split()),map(float,lines[14].split())]\n",
      "result5 = [map(float,lines[17].split()),map(float,lines[18].split())]\n",
      "fig = plt.figure()\n",
      "ax = fig.add_subplot(111)\n",
      "#fig.set_size_inches(6.83,4)\n",
      "fig.set_size_inches(10,7)\n",
      "\n",
      "\n",
      "ax.set_xlabel('counting error rate (offset>0)')\n",
      "ax.set_ylabel('average miscount')\n",
      "ax.plot(result1[1],result1[0],'ro-',result2[1],result2[0],'go-',result3[1],result3[0],'bo-',result4[1],result4[0],'yo-',result5[1],result5[0],'ko-')\n",
      "#ax.set_xlim(0,0.2)\n",
      "#ax.set_ylim(0,20)\n",
      "ax.axis(ymax=10, ymin=-2)\n",
      "ax.legend(('metagenome data','random k-mers','reads with error','reads without error','E.coli reads'),loc='upper left',prop={'size':8})\n",
      "fig_file = '../figure/average_offset_vs_fpr.eps'\n",
      "plt.savefig(fig_file,dpi=300)\n",
      "\n",
      "#print result1\n",
      "#print result2\n",
      "#print result3\n",
      "#print result4"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Figure 6 - counting error rate vs miscount"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "y-axis is the average of (offset/correct_count) for each k-mer\n",
      "\n",
      "Since the high diversity dataset, most of the accurate counts are 1, so for smaller hash table(high error rate), the offset(miscount) may be 2 or 3. That percentage will be 100%-200%, which is the case in the figure while counting error rate >0.7"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ht_size = \"100000,200000,400000,600000,800000,1000000,1200000\"\n",
      "HT_SIZE_array = map(int,ht_size.split(','))\n",
      "\n",
      "\n",
      "file_obj = open(datadir+'fp_assessment.out','r')\n",
      "lines = file_obj.readlines()\n",
      "result1 = numpy.array([map(float,lines[3].split()),map(float,lines[2].split())])\n",
      "result1[0] *= 100.\n",
      "result2 = numpy.array([map(float,lines[7].split()),map(float,lines[6].split())])\n",
      "result2[0] *= 100.\n",
      "result3 = numpy.array([map(float,lines[11].split()),map(float,lines[10].split())])\n",
      "result3[0] *= 100.\n",
      "result4 = numpy.array([map(float,lines[15].split()),map(float,lines[14].split())])\n",
      "result4[0] *= 100.\n",
      "result5 = numpy.array([map(float,lines[19].split()),map(float,lines[18].split())])\n",
      "result5[0] *= 100.\n",
      "\n",
      "fig = plt.figure()\n",
      "ax = fig.add_subplot(111)\n",
      "#fig.set_size_inches(6.83,4)\n",
      "fig.set_size_inches(10,7)\n",
      "\n",
      "\n",
      "ax.set_xlabel('counting error rate (miscount > 0)')\n",
      "ax.set_ylabel('average miscount (percent)')\n",
      "ax.plot(result1[1],result1[0],'ro-',result2[1],result2[0],'go-',result3[1],result3[0],'bo-',result4[1],result4[0],'yo-',result5[1],result5[0],'ko-')\n",
      "#ax.set_xlim(0,1)\n",
      "ax.set_ylim(0,100)\n",
      "ax.legend(('metagenome data','random k-mers','reads with 1% error','reads without error','E.coli reads'),loc='upper left',prop={'size':8})\n",
      "fig_file = '../figure/percent_offset_vs_fpr.eps'\n",
      "plt.savefig(fig_file,dpi=300)\n",
      "#ax.axis(ymax=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Figure 7 - Percentage of the unique k-mers starting in different position in reads"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "file17 = open(datadir+\"ecoli_ref.fastq.pos17.abund1\",'r')\n",
      "file32 = open(datadir+\"ecoli_ref.fastq.pos32.abund1\",'r')\n",
      "\n",
      "list1 = []\n",
      "list2 = []\n",
      "x1 = []\n",
      "x2 = []\n",
      "\n",
      "for line in file17:\n",
      "    line = line.rstrip()\n",
      "    fields = line.split()\n",
      "    if fields[1] != '0':\n",
      "        x1.append(float(fields[0]))\n",
      "        list1.append(float(fields[1]))\n",
      "\n",
      "for line in file32:\n",
      "    line = line.rstrip()\n",
      "    fields = line.split()\n",
      "    if fields[1] != '0':\n",
      "        x2.append(float(fields[0]))\n",
      "        list2.append(float(fields[1]))\n",
      "\n",
      "fig = plt.figure()\n",
      "ax = fig.add_subplot(111)\n",
      "fig.set_size_inches(6.83,4)\n",
      "        \n",
      "ax.set_xlabel(\"Starting position of k-mer in read\")\n",
      "ax.set_ylabel(\"Number of abund=1 k-mers at that position\")\n",
      "\n",
      "ax.plot(x1,list1,'r-')\n",
      "ax.plot(x2,list2,'b-')\n",
      "ax.legend(('k=17','k=32'), loc='upper left',prop={'size':12})\n",
      "#plt.ylim(0,10000000)\n",
      "ax.set_xlim(0,100)\n",
      "\n",
      "plt.savefig(\"../figure/perc_unique_pos.eps\",dpi=300)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Tables"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Table 3\n",
      "==========\n",
      "Iterative low-memory k-mer trimming. The results of trimming reads at unique (erroneous) k-mers from a 1.41Gbp short-read data set in under 30 MB of RAM. After each iteration, we measured the total number of distinct k-mers in the data set, the total number of unique (and likely erroneous, with frequency = 1) k-mers remaining, and the number of unique k-mers present at the 3\u2019 end of reads."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def human_format(num):\n",
      "    magnitude = 0\n",
      "    while num >= 1000:  # TODO: handle negative numbers?\n",
      "        magnitude += 1\n",
      "        num /= 1000.0\n",
      "    # add more suffixes if you need them\n",
      "    return '%.1f%s' % (num, ['', 'K', 'M', 'G', 'T', 'P'][magnitude])\n",
      "\n",
      "print('the answer is %s' % human_format(7436313))  # prints 'the answer is 7.44M'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# get fp rate of filter-abund,  get discarded percentage of bases and get processed_bases(for other trimming method output file)\n",
      "# from ecoli_ref.fastq.r1.fq.out  -< filter-abund-single.py\n",
      "def read_out_file(file_out):\n",
      "\n",
      "    fp_out = open(file_out,'r')\n",
      "    for line in fp_out:\n",
      "        if \"discarded\" in line:\n",
      "            percent = line.split()[1]\n",
      "        if \"fp rate estimated to be\" in line:\n",
      "            fp = float(line.split()[5])\n",
      "        if \"processed\" in line:\n",
      "            processed_bases = int(line.split()[1])\n",
      "        \n",
      "    return \"{:.1f}%\".format(fp * 100), percent, processed_bases\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def read_diginorm_out_file(file_out):\n",
      "\n",
      "    fp_out = open(file_out,'r')\n",
      "    for line in fp_out:\n",
      "        if \"DONE with\" in line:\n",
      "            percent = float(line.split()[-2])\n",
      "            kept_reads = line.split()[-6]\n",
      "            all_reads = line.split()[-4]\n",
      "        if \"fp rate estimated to be\" in line:\n",
      "            fp = float(line.split()[5])\n",
      "\n",
      "    return \"{:.1f}%\".format(fp * 100),\"{:.1f}%\".format(percent) , '{:,}'.format(int(kept_reads)),'{:,}'.format(int(all_reads))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#file_out = \"../data/ecoli_ref.fastq.ka.r1.fq.hist\"\n",
      "# get number of unique k-mers(freq=1) and number of total distinct k-mers.\n",
      "def read_hist_file(file_out):\n",
      "    fp_out = open(file_out,'r')\n",
      "    for line in fp_out:\n",
      "        line = line.rstrip()\n",
      "        fields = line.split()\n",
      "        if fields[0] == '1':\n",
      "            unique_num = int(fields[1])\n",
      "        all_num = int(fields[2])\n",
      "    return human_format(unique_num),human_format(all_num)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# ecoli_ref.fastq.kh.e_coli_ref_hist\n",
      "def read_e_coli_ref_hist_file(file_out):\n",
      "    fp_out = open(file_out,'r')\n",
      "    for line in fp_out:\n",
      "        line = line.rstrip()\n",
      "        fields = line.split()\n",
      "        if fields[0] == '0':\n",
      "            missing_kmers = str(fields[1])\n",
      "    return missing_kmers"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#file_out = \"../data/ecoli_ref.fastq.ka.r1.fq.endcount\"\n",
      "def read_endcount_file(file_out):\n",
      "    \n",
      "    fp_out = open(file_out,'r')\n",
      "    for line in fp_out:\n",
      "        line = line.rstrip()\n",
      "        fields = line.split()\n",
      "        perc = float(fields[-1])\n",
      "    \n",
      "    return \"{:.1f}%\".format(perc * 100)\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "------------\n",
      "start from raw data\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "out1 = read_out_file(\"../data/ecoli_ref.fastq.r1.fq.out\")\n",
      "hist1 = read_hist_file(\"../data/ecoli_ref.fastq.r1.fq.hist\")\n",
      "endcount1 = read_endcount_file(\"../data/ecoli_ref.fastq.r1.fq.endcount\")\n",
      "out2 = read_out_file(\"../data/ecoli_ref.fastq.r2.fq.out\")\n",
      "hist2 = read_hist_file(\"../data/ecoli_ref.fastq.r2.fq.hist\")\n",
      "endcount2 = read_endcount_file(\"../data/ecoli_ref.fastq.r2.fq.endcount\")\n",
      "out3 = read_out_file(\"../data/ecoli_ref.fastq.r3.fq.out\")\n",
      "hist3 = read_hist_file(\"../data/ecoli_ref.fastq.r3.fq.hist\")\n",
      "endcount3 = read_endcount_file(\"../data/ecoli_ref.fastq.r3.fq.endcount\")\n",
      "out4 = read_out_file(\"../data/ecoli_ref.fastq.r4.fq.out\")\n",
      "hist4 = read_hist_file(\"../data/ecoli_ref.fastq.r4.fq.hist\")\n",
      "endcount4 = read_endcount_file(\"../data/ecoli_ref.fastq.r4.fq.endcount\")\n",
      "out5 = read_out_file(\"../data/ecoli_ref.fastq.r5.fq.out\")\n",
      "hist5 = read_hist_file(\"../data/ecoli_ref.fastq.r5.fq.hist\")\n",
      "endcount5 = read_endcount_file(\"../data/ecoli_ref.fastq.r5.fq.endcount\")\n",
      "out6 = read_out_file(\"../data/ecoli_ref.fastq.r6.fq.out\")\n",
      "hist6 = read_hist_file(\"../data/ecoli_ref.fastq.r6.fq.hist\")\n",
      "endcount6 = read_endcount_file(\"../data/ecoli_ref.fastq.r6.fq.endcount\")\n",
      "\n",
      "# untrimmed\n",
      "endcount0 = read_endcount_file(\"../data/ecoli_ref.fastq.endcount\")\n",
      "hist0 = read_hist_file(\"../data/ecoli_ref.fastq.hist\")\n",
      "\n",
      "# quality filtered by FASTX\n",
      "endcount00 = read_endcount_file(\"../data/ecoli_ref-trim.fastq.endcount\")\n",
      "# to get number of freq=1 unique k-mers and total distinct k-mers in trimmed data set\n",
      "hist00 = read_hist_file(\"../data/ecoli_ref-trim.fastq.hist\")\n",
      "# to get processed bases(in trimmed data), to get % of trimmed bases compared to  processed bases in full data \n",
      "out00 = read_out_file(\"../data/ecoli_ref-trim.fastq.r1.fq.out\")\n",
      "\n",
      "# quality filtered by seqtk using different parameters\n",
      "endcount_seqtk = read_endcount_file(\"../data/ecoli_ref.fastq.seqtk-trimmed.fastq.endcount\")\n",
      "hist_seqtk = read_hist_file(\"../data/ecoli_ref.fastq.seqtk-trimmed.fastq.hist\")\n",
      "out_seqtk = read_out_file(\"../data/ecoli_ref.fastq.seqtk-trimmed.r1.fastq.out\")\n",
      "\n",
      "endcount_seqtk_q001 = read_endcount_file(\"../data/ecoli_ref.fastq.seqtk-trimmed-q001.fastq.endcount\")\n",
      "hist_seqtk_q001 = read_hist_file(\"../data/ecoli_ref.fastq.seqtk-trimmed-q001.fastq.hist\")\n",
      "out_seqtk_q001 = read_out_file(\"../data/ecoli_ref.fastq.seqtk-trimmed-q001.r1.fastq.out\")\n",
      "\n",
      "endcount_seqtk_b3e5 = read_endcount_file(\"../data/ecoli_ref.fastq.seqtk-trimmed-b3e5.fastq.endcount\")\n",
      "hist_seqtk_b3e5 = read_hist_file(\"../data/ecoli_ref.fastq.seqtk-trimmed-b3e5.fastq.hist\")\n",
      "out_seqtk_b3e5 = read_out_file(\"../data/ecoli_ref.fastq.seqtk-trimmed-b3e5.r1.fastq.out\")\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "FASTX:\n",
      "\n",
      "fastq_quality_filter -Q33 -q 30 -p 50 -i ecoli_ref.fastq >ecoli_ref-trim.fastq\n",
      "\n",
      "SEQTK with different parameters:\n",
      "\n",
      "seqtk trimfq \n",
      "\n",
      "seqtk trimfq -q 0.01 \n",
      "\n",
      "seqtk trimfq -b 3 -e 5 \n",
      "\n",
      "\n",
      "total k-mers means \"total number of different k-mers\"\n",
      "\n",
      "unique k-mers means \"total number of k-mers with frequency as 1\"\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "table_format = '{:28s}{:>10s}{:>16s}{:>16s}{:>18s}{:>27s}'\n",
      "print table_format.format('method','FP rate','bases trimmed','total k-mers',\\\n",
      "                                           'unique k-mers','unique k-mers at 3\\' end')\n",
      "#print '{:35s}{:>10s}{:>20s}{:>20s}{:>20s}{:>20s}'.format('iteration','FP rate','bases trimmed','total k-mers',\\\n",
      "#                                          'unique k-mers','unique k-mers at 3\\' end')\n",
      "#print out1\n",
      "print '-'*120\n",
      "print table_format.format('data to process','-','-',hist0[1], hist0[0], endcount0)\n",
      "print table_format.format('khmer iteration 1',out1[0],out1[1],hist1[1], hist1[0], endcount1)\n",
      "print table_format.format('khmer iteration 2',out2[0],out2[1],hist2[1], hist2[0], endcount2)\n",
      "print table_format.format('khmer iteration 3',out3[0],out3[1],hist3[1], hist3[0], endcount3)\n",
      "print table_format.format('khmer iteration 4',out4[0],out4[1],hist4[1], hist4[0], endcount4)\n",
      "print table_format.format('khmer iteration 5',out5[0],out5[1],hist5[1], hist5[0], endcount5)\n",
      "print table_format.format('khmer iteration 6',out6[0],out6[1],hist6[1], hist6[0], endcount6)\n",
      "print table_format.format('filtered by FASTX','-',\"{:.1f}%\".format((1-float(out00[2])/out1[2]) * 100),hist00[1], hist00[0], endcount00)\n",
      "print table_format.format('filtered by seqtk(default)','-',\"{:.1f}%\".format((1-float(out_seqtk[2])/out1[2]) * 100),hist_seqtk[1], hist_seqtk[0], endcount_seqtk)\n",
      "print table_format.format('filtered by seqtk(-q 0.01)','-',\"{:.1f}%\".format((1-float(out_seqtk_q001[2])/out1[2]) * 100),hist_seqtk_q001[1], hist_seqtk_q001[0], endcount_seqtk_q001)\n",
      "print table_format.format('filtered by seqtk(-b 3 -e 5)','-',\"{:.1f}%\".format((1-float(out_seqtk_b3e5[2])/out1[2]) * 100),hist_seqtk_b3e5[1], hist_seqtk_b3e5[0], endcount_seqtk_b3e5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Here we expect the fp rate for the first iteration is ~80%, with this fp rate, the optimal number of hash table is 1.\n",
      "\n",
      "The size of hash table is :\n",
      "\n",
      ">>> math.log(0.8,0.5)\n",
      "\n",
      "0.3219280948873623\n",
      "\n",
      ">>> math.log(0.2)\n",
      "\n",
      "-1.6094379124341003\n",
      "\n",
      ">>> 41553294/math.log(0.2)\n",
      "\n",
      "\n",
      "-25818513.208226312\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Table 4\n",
      "==========\n",
      "Low-memory digital normalization. The results of digitally normalizing a 5m read E. coli data set to C=20 with k=20 under several memory usage/error rates. The error rate (column 1) is empirically determined. We measured reads remaining, number of \u201ctrue\u201d k-mers that were removed during the normalization process, and the number of total k-mers remaining. Note: at high error rates, reads are erroneously removed due to inflation of k-mer counts."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#ecoli_ref.fastq.keep20M.fq.kh.e_coli_ref_hist \n",
      "diginorm_file={}\n",
      "hist_file = {}\n",
      "missed_kmers = {}\n",
      "for size in ['10M','20M','40M','60M','120M','240M','2400M']:\n",
      "    diginorm_file[size] = read_diginorm_out_file(\"../data/norm\"+size+\".out\")\n",
      "    hist_file[size] = read_hist_file(\"../data/ecoli_ref.fastq.keep\"+size+\".fq.hist\")\n",
      "    missed_kmers[size] = read_e_coli_ref_hist_file(\"../data/ecoli_ref.fastq.keep\"+size+\".fq.kh.e_coli_ref_hist\")\n",
      "missed_kmers['all'] = read_e_coli_ref_hist_file(\"../data/ecoli_ref.fastq.kh.e_coli_ref_hist\")\n",
      "hist_file['all'] = read_hist_file(\"../data/ecoli_ref.fastq.hist\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "table_format = '{:>20s}{:>10s}{:>16s}{:>20s}{:>25s}{:>27s}'\n",
      "print table_format.format('memory','FP rate','retained reads','retained reads %','true k-mers removed','retained total k-mers')\n",
      "\n",
      "print '-'*70\n",
      "# all 5m reads ecoli data set\n",
      "print table_format.format('[before diginorm]','-',diginorm_file['10M'][3],'100.0%',missed_kmers['all'],hist_file['all'][1])\n",
      "\n",
      "for size in ['10M','20M','40M','60M','120M','240M','2400M']:\n",
      "    print table_format.format(size,diginorm_file[size][0],diginorm_file[size][2],diginorm_file[size][1],missed_kmers[size],hist_file[size][1])\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Supplementary - determine the optimal parameters of hash tables to use\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import math\n",
      "\n",
      "n1 = 561178082\n",
      "n2 = 1060354144\n",
      "n3 = 1445923389\n",
      "n4 = 1770589216\n",
      "n5 = 2121474237\n",
      "ns = [n1,n2,n3,n4,n5]\n",
      "\n",
      "print ns"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "if false positive rate is fixed, number of hash tables is fixed for minimum memory \n",
      "\n",
      "0.01 ~ 6\n",
      "\n",
      "0.05 ~ 4\n",
      "\n",
      "0.2 ~ 2\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def optimal(f,N):\n",
      "    M = math.log(f,0.6185)*N\n",
      "    print M/N\n",
      "    Z = math.log(2)*(M/float(N))\n",
      "    intZ = int(Z)\n",
      "    if intZ == 0:\n",
      "        intZ = 1\n",
      "    H = int(M/intZ)\n",
      "    f1 = (1-math.exp(-N/(M/Z)))**Z\n",
      "    f2 = (1-math.exp(-N/float(H)))**intZ\n",
      "    return M,Z,intZ, H, f1, f2\n",
      "\n",
      "def optimal2(f,N):\n",
      "    Z = math.log(f,0.5)\n",
      "    intZ = int(Z)\n",
      "    if intZ == 0:\n",
      "        intZ = 1\n",
      "    M = Z/math.log(2)*N\n",
      "        \n",
      "    #print M/N\n",
      "    H = int(M/intZ)\n",
      "    f1 = (1-math.exp(-N/(M/Z)))**Z\n",
      "    f2 = (1-math.exp(-N/float(H)))**intZ\n",
      "    return M,Z,intZ, H, f1, f2\n",
      "\n",
      "m1 = []\n",
      "h1 = []\n",
      "n1 = []\n",
      "for n in ns:\n",
      "    s= optimal2(0.01,n)\n",
      "    m1.append(s[0])\n",
      "    n1.append(str(s[2]))\n",
      "    h1.append(str(s[3]))\n",
      "\n",
      "m5 = []\n",
      "h5 = []\n",
      "n5 = []\n",
      "for n in ns:\n",
      "    s= optimal2(0.05,n)\n",
      "    m5.append(s[0])\n",
      "    n5.append(str(s[2]))\n",
      "    h5.append(str(s[3]))\n",
      "\n",
      "m20 = []\n",
      "h20 = []\n",
      "n20 = []\n",
      "for n in ns:\n",
      "    s= optimal2(0.2,n)\n",
      "    m20.append(s[0])\n",
      "    n20.append(str(s[2]))\n",
      "    h20.append(str(s[3]))\n",
      "print h1, n1, h5,n5"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "\n",
      "Table: optimal size and number of hash tables to use, to minimize memory usage for expected false positive rate \n",
      "-------\n",
      "used in benchmark\n",
      "\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print 'optimal size and number of hash tables to use, to minimize memory usage for expected false positive rate'\n",
      "print '='*100\n",
      "print '{:10s}{:30s}{:20s}{:20s}{:20s}'.format('Data set','size of file(GB)','fpr=1%',\\\n",
      "                        'fpr=5%','fpr=20%')\n",
      "print '-'*100\n",
      "print '{:10s}{:30s}{:20s}{:20s}{:20s}'.format('subset1','1.90',h1[0]+' X '+n1[0],h5[0]+' X '+n5[0],h20[0]+' X '+n20[0])\n",
      "print '{:10s}{:30s}{:20s}{:20s}{:20s}'.format('subset2','2.17',h1[1]+' X '+n1[1],h5[1]+' X '+n5[1],h20[1]+' X '+n20[1])\n",
      "print '{:10s}{:30s}{:20s}{:20s}{:20s}'.format('subset3','3.14',h1[2]+' X '+n1[2],h5[2]+' X '+n5[2],h20[2]+' X '+n20[2])\n",
      "print '{:10s}{:30s}{:20s}{:20s}{:20s}'.format('subset4','4.05',h1[3]+' X '+n1[3],h5[3]+' X '+n5[3],h20[3]+' X '+n20[3])\n",
      "print '{:10s}{:30s}{:20s}{:20s}{:20s}'.format('subset5','5.00',h1[4]+' X '+n1[4],h5[4]+' X '+n5[4],h20[4]+' X '+n20[4])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "optimal number of hash tables is determined by expected false positive rate only\n",
      "---------"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "\n",
      "x=[]\n",
      "y=[]\n",
      "f=0.0001\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "while f<1:\n",
      "    Z = math.log(f,0.5)\n",
      "    x.append(f)\n",
      "    y.append(Z)\n",
      "    f = f+0.0001\n",
      "fig = plt.figure(figsize=(6,5))\n",
      "ax = fig.add_subplot(111)\n",
      "\n",
      "x2=[0.001,0.005,0.01,0.03,0.05,0.1,0.2]\n",
      "y2 = []\n",
      "for f in x2:\n",
      "    y2.append(math.log(f,0.5))\n",
      "              \n",
      "ax.plot(x,y)\n",
      "for x, y in zip(x2, y2):\n",
      "    ax.plot((x,),(y,), 'ro')\n",
      "    print x,y\n",
      "    ax.text(x, y, '%.3f, %.2f' % (float(x),float(y)))\n",
      "\n",
      "    \n",
      "\n",
      "ax.set_xscale('log')\n",
      "ax.set_xlabel('false positive rate')\n",
      "ax.set_ylabel('optimal number of hash tables')\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "estimated minimum required memory depends on expected false positive rate and number of unique k-mers in the data set to count\n",
      "----------"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "\n",
      "def optimal3(f,N):\n",
      "    Z = math.log(f,0.5)\n",
      "    intZ = int(Z)\n",
      "    if intZ == 0:\n",
      "        intZ = 1\n",
      "    M = Z/math.log(2)*N\n",
      "    return M\n",
      "\n",
      "fig = plt.figure(figsize=(6,5))\n",
      "ax = fig.add_subplot(111)\n",
      "\n",
      "\n",
      "fs =[0.001,0.005,0.01,0.03,0.05,0.1,0.2]\n",
      "for f in fs:\n",
      "    Ns = []\n",
      "    Ms = []\n",
      "    #print f\n",
      "    N=0\n",
      "    while N<1e10:\n",
      "     #   print N\n",
      "        M = optimal3(f,N)\n",
      "        Ns.append(N)\n",
      "        Ms.append(M/1e9)\n",
      "        N = N+1e9\n",
      "    #print Ns,Ms\n",
      "    ax.plot(Ns,Ms,'-',label='fpr='+str(f))\n",
      "#ax = fig.add_subplot(111)\n",
      "#ax.plot(5e9,5e10,'o')\n",
      "#ax.plot(4e9,4e10,'o')\n",
      "fs =[0.01,0.05,0.2]\n",
      "\n",
      "for f in fs:\n",
      "    Ns = []\n",
      "    Ms = []\n",
      "    #print f\n",
      "    for n in ns:\n",
      "     #   print N\n",
      "        M = optimal3(f,n)\n",
      "        Ms.append(M)\n",
      "        Ns.append(n)\n",
      "\n",
      "    #print Ns,Ms\n",
      "    #ax.plot(Ns,Ms)\n",
      "\n",
      "ax.set_xlabel('# of unique k-mers')\n",
      "ax.set_ylabel('estimated minimum required memory (G)')\n",
      "ax.legend(loc='upper left')\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}